{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Twittconomy analyzer #\n",
    "## Análizador de sentimiento ##\n",
    "\n",
    "**Twittconomy analizer** es un programa especializado que pretende bajar los twitts de diferentes personas, instituciones, corporaciones, etc. que tienen un gran influencia en los mercados internacionales, con el propósito de determinar como un Twitt puede cambiar la valuación de la acciones en la bolsa. \n",
    "\n",
    "**Contexto**\n",
    "Se presentó el proyecto ante la empresa Twitter, la cual respondió de manera positiva al proyecto debido a que actualmente no existe un programa específico que cubra con esta necesidad. Su respuesta se presenta a continuación.\n",
    "\n",
    "<img style=\"float: left; margin: 15px 15px 15px 15px;\" src=\"untitled1.png\" title=\"untitled1\" width=\"250\" height=\"560\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "La primera parte del código es para bajar las librerias necesarias para poder correr el programa. Principalmente tenemos los siguientes:\n",
    "\n",
    "**Textblob:** es una librería que dan acceso rápido al API que da métodos básicos y fáciles para correr tareas fáciles de proceso de lenguaje natural. Se construye en base de NLTK.  \n",
    "\n",
    "**Nltk:** es la librería base de Textblob que funciona para cuentiones de investigación. \n",
    "\n",
    "**Tweepy:** es la librería principal para hacer análisis de sentimientos en los Twitts considerando las palabras de las personas y las reacciones de las personas que leen los Twitts.\n",
    "\n",
    "**Pandas:** librería convencional para generar estructuras y análisis de datos. En este caso para apoyar el arreglo matricial.\n",
    "\n",
    "**Numpy:** Librería que funciona exclusivamente para operaciones matemáticas.\n",
    "\n",
    "**Seaborn:** es una librería basado en matplotlib, es para generar gráficas especializadas. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'textblob'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-f11d0776709c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtextblob\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mTextBlob\u001b[0m \u001b[1;31m#libreria que hace el análisis\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnltk\u001b[0m \u001b[1;31m#libreria que trabaja el procesamiento de lenguaje natural\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'punkt'\u001b[0m\u001b[1;33m)\u001b[0m   \u001b[1;31m# esta parte no sé por qué es requerida,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'averaged_perceptron_tagger'\u001b[0m\u001b[1;33m)\u001b[0m   \u001b[1;31m#esta tampoco, pero si no se llaman a ambas, no jala... jaja\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtweepy\u001b[0m\u001b[1;31m# librería que trabaja con la API para obtener datos de tweeter\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'textblob'"
     ]
    }
   ],
   "source": [
    "from textblob import TextBlob #libreria que hace el análisis\n",
    "import nltk #libreria que trabaja el procesamiento de lenguaje natural\n",
    "nltk.download('punkt')   # esta parte no sé por qué es requerida, \n",
    "nltk.download('averaged_perceptron_tagger')   #esta tampoco, pero si no se llaman a ambas, no jala... jaja\n",
    "import tweepy# librería que trabaja con la API para obtener datos de tweeter\n",
    "import pandas as pd  #Pandas para hacer dataframes(tablas de datos)\n",
    "import numpy as np   #numpy para operaciones básicas\n",
    "import seaborn as sns   #Graficas\n",
    "import matplotlib.pyplot as plt  #más gráficas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Posterior a esta parte del código se introducen las llaves del API, que son lo accesos a Twitter desde el textblob. \n",
    "\n",
    "El consumer key y consumer secret son los códigos del usuario que se integrará a las bases de datos de Twitter mientras que lo Token access son la claves únicas del protal. El secret serian las contraseñas y los que vienen sin secret sería un análogo a los usuarios. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tweepy' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-5a47bb4ba68b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0maccess_token_secret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"7H8EVyhQB1zpKut71HbQn2BYshDQTuNjaOnS083o6CKQ0\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[0mauth\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtweepy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOAuthHandler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconsumer_key\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconsumer_secret\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[0mauth\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_access_token\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maccess_token\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccess_token_secret\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'tweepy' is not defined"
     ]
    }
   ],
   "source": [
    "#En esta parte solo se utilizan las llaves de la API para accceder a los datos de Twitter.\n",
    "\n",
    "consumer_key = \"consumer KEY\"\n",
    "\n",
    "consumer_secret = \"Customer Secret\" \n",
    "\n",
    "access_token = \"Access Token\"\n",
    "\n",
    "access_token_secret = \"Access_token_secret\"\n",
    "\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "\n",
    "api = tweepy.API(auth)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La siguiente parte del código solamente se colocan diferentes cuentas de twitter que en experiencia, son las que tienen una mayor contribución en la bolsa. Además de tomar temas de la bolsa. Se crea una tabla por medio de un dataframe y se baja el listado directo de un archivo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Account</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>realDonaldTrump</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>haaretzcom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ONU_es</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CNBC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>nytimes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>washingtonpost</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Tesla</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>JPMAM_UKAdviser</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>blackrock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>BlackRockMX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>MoodysLatAm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>MoodysInvSvc</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Account\n",
       "0   realDonaldTrump\n",
       "1        haaretzcom\n",
       "2                FT\n",
       "3            ONU_es\n",
       "4              CNBC\n",
       "5           nytimes\n",
       "6    washingtonpost\n",
       "7          business\n",
       "8             Tesla\n",
       "9   JPMAM_UKAdviser\n",
       "10        blackrock\n",
       "11      BlackRockMX\n",
       "12      MoodysLatAm\n",
       "13     MoodysInvSvc"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#crear dataframe de cuentas de twitter\n",
    "\n",
    "accounts = pd.read_csv(\"accounts.csv\")\n",
    "accounts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al igual que en el punto anterior, se genera una tabla en la que se incluye el nombre de las empresas que se encuentran cotizando en la bolsa. En este caso solo se tomaron 5 empresas y solo los encabezados. Se puede hacer de más empresas y más información de cada una."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>action</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>$FB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>$AMZN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>$NFLX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>$GOOGL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>$AAPL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   action\n",
       "0     $FB\n",
       "1   $AMZN\n",
       "2   $NFLX\n",
       "3  $GOOGL\n",
       "4   $AAPL"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Dataframe de acciones\n",
    "stocks = pd.read_csv(\"actions.csv\")\n",
    "stocks.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación, se define una función llamada analysis, la cual baja los algoritmos del Textblob para permitir operar un analisis de sentimiento. Al final  solamente se indica que el preceso de la API determine un valor. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#función que hace el análisis de sentimiento de tweet,(Falta crear filtro que omita links y basura no textual, que no nos sirve para el análisis)\n",
    "def analysis(tweet):\n",
    "    analysis = TextBlob(tweet) \n",
    "    return analysis.sentiment.polarity #Falta documentar cómo funciona esta parte, pero básicamente utiliza una base de datos de adjetivos\n",
    "                                        # en XMl que tiene una calificación de sentimiento ya sea negativo o positivo,\n",
    "                                        # de cada frase saca un promedio de esos adjetivos\n",
    "                                        #https://github.com/sloria/TextBlob/blob/dev/textblob/en/en-sentiment.xml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El siguiente punto es más completo se define tweets, lo que determina que se baje toda la información que existe de Twitter de una direección específica. Dentro de los paréntesis se indica el nombre de la cuenta y la cantidad de twitts que se  van a usar. \n",
    "\n",
    "Debajo se define una nueva función que por medio de \"Tweets\" arregla la información de la persona en una matriz que por matriz donde se consideran diferentes aspectos como el usuario, la dirección del twitt, la longitud la cantidad de likes, la fecha en el que fue escrito, el sentimiento (en la sección del sentimiento se integra la función de \"analysis\") y la cantidad de retweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#crear data frame, que contiene los datos de usuario(tweet, identificación del tweet, longitud del tweet, fecha, likes, retweets y análisis de sentimiento)\n",
    "tweets = api.user_timeline(screen_name=\"realDonaldTrump\", count=100)\n",
    "    \n",
    "def tweets_to_data_frame(tweets):\n",
    "        df = pd.DataFrame(data=[tweet.text for tweet in tweets], columns=['tweets'])\n",
    "        df['user']= np.array(screen_name for tweet in tweets)\n",
    "        df['id'] = np.array([tweet.id for tweet in tweets])\n",
    "        df['len'] = np.array([len(tweet.text) for tweet in tweets])\n",
    "        df['date'] = np.array([tweet.created_at for tweet in tweets])\n",
    "        df['likes'] = np.array([tweet.favorite_count for tweet in tweets])\n",
    "        df['retweets'] = np.array([tweet.retweet_count for tweet in tweets])\n",
    "        df['sentiment'] = np.array([round(analysis(tweet.text),2) for tweet in tweets]) \n",
    "\n",
    "        return df\n",
    "    \n",
    "df= tweets_to_data_frame(tweets)    \n",
    "\n",
    "\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La función siguiente solo transforma el archivo a Json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#esta parte convierte el dataframe a un archivo JSON\n",
    "\n",
    "df.to_json(\"tweets.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En las siguientes líneas, se muestra el análisis de sentimiento impreso, esto solamente es para mostrarse un ejemplo de como se toma la información necesaria por twitt, se presenta la polatidad y la subjetividad de acuerdo a la expresión del individuo. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RT @charliebilello: % Below 52-week High...\n",
      "$FB: -40%\n",
      "$AAPL: -20%\n",
      "$AMZN: -26%\n",
      "$NFLX: -36%\n",
      "$NVDA: -49%\n",
      "$GOOGL: -20%\n",
      "Sentiment(polarity=0.16, subjectivity=0.5399999999999999)\n",
      "\n",
      "$AAPL if $AAPL retraces to 195, 197.5 or 200 area its a gift. It will be 1999 all over again. Or maybe it just keep… https://t.co/aAXPwfjeIn\n",
      "Sentiment(polarity=0.0, subjectivity=0.0)\n",
      "\n",
      "RT @charliebilello: % Below 52-week High...\n",
      "$FB: -40%\n",
      "$AAPL: -20%\n",
      "$AMZN: -26%\n",
      "$NFLX: -36%\n",
      "$NVDA: -49%\n",
      "$GOOGL: -20%\n",
      "Sentiment(polarity=0.16, subjectivity=0.5399999999999999)\n",
      "\n",
      "ياكثر الاسئله عن $AAPL \n",
      "\n",
      "رغم انه سهم غثيث .. \n",
      "\n",
      "لكن : سعره اليوم 185$ \n",
      "\n",
      "بكرة ممكن عنده ارتداد مع السوق بشكل اجمالي… https://t.co/wO9fVw7MA6\n",
      "Sentiment(polarity=0.0, subjectivity=0.0)\n",
      "\n",
      "RT @financialbuzz: Watch Us Report LIVE from the Floor of the NYSE! This weeks weekly wrap-up includes $RHT $IBM $UA $AAPL $FIT $FB $S $GE…\n",
      "Sentiment(polarity=0.2852272727272727, subjectivity=0.45)\n",
      "\n",
      "RT @charliebilello: % Below 52-week High...\n",
      "$FB: -40%\n",
      "$AAPL: -20%\n",
      "$AMZN: -26%\n",
      "$NFLX: -36%\n",
      "$NVDA: -49%\n",
      "$GOOGL: -20%\n",
      "Sentiment(polarity=0.16, subjectivity=0.5399999999999999)\n",
      "\n",
      "Netflix’s ‘death cross’ (50 moving average under, 200 moving average) is the third for FAANG stocks and Nasdaq Comp… https://t.co/KKo5dr2Vjz\n",
      "Sentiment(polarity=-0.075, subjectivity=0.19999999999999998)\n",
      "\n",
      "RT @financialbuzz: Watch Us Report LIVE from the Floor of the NYSE! This weeks weekly wrap-up includes $NVDA $AAPL $TSN $HD $GE $TLRY $CRON…\n",
      "Sentiment(polarity=0.17045454545454544, subjectivity=0.5)\n",
      "\n",
      "RT @financialbuzz: Watch Us Report LIVE from the Floor of the NYSE! This weeks weekly wrap-up includes $RHT $IBM $UA $AAPL $FIT $FB $S $GE…\n",
      "Sentiment(polarity=0.2852272727272727, subjectivity=0.45)\n",
      "\n",
      "RT @financialbuzz: Watch Us Report LIVE from the Floor of the NYSE! This weeks weekly wrap-up includes $RHT $IBM $UA $AAPL $FIT $FB $S $GE…\n",
      "Sentiment(polarity=0.2852272727272727, subjectivity=0.45)\n",
      "\n",
      "RT @financialbuzz: Watch Us Report LIVE from the Floor of the NYSE! This weeks weekly wrap-up includes $RHT $IBM $UA $AAPL $FIT $FB $S $GE…\n",
      "Sentiment(polarity=0.2852272727272727, subjectivity=0.45)\n",
      "\n",
      "RT @financialbuzz: Watch Us Report LIVE from the Floor of the NYSE! This weeks weekly wrap-up includes $RHT $IBM $UA $AAPL $FIT $FB $S $GE…\n",
      "Sentiment(polarity=0.2852272727272727, subjectivity=0.45)\n",
      "\n",
      "RT @financialbuzz: Watch Us Report LIVE from the Floor of the NYSE! This weeks weekly wrap-up includes $NVDA $AAPL $TSN $HD $GE $TLRY $CRON…\n",
      "Sentiment(polarity=0.17045454545454544, subjectivity=0.5)\n",
      "\n",
      "How is Cramer Charitable Trust doing ?\n",
      "\n",
      "$nvda $aapl $fb $msft $nflx\n",
      "Sentiment(polarity=0.6, subjectivity=0.8)\n",
      "\n",
      "RT @financialbuzz: Watch Us Report LIVE from the Floor of the NYSE! This weeks weekly wrap-up includes $NVDA $AAPL $TSN $HD $GE $TLRY $CRON…\n",
      "Sentiment(polarity=0.17045454545454544, subjectivity=0.5)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#imprimir tweets y su análiss de sentimiento dependiendo de la palabra, hashtag, stocktag... que tú desees.\n",
    "\n",
    "public_tweets = api.search('$AAPL')     #Elige el tema a imprimir\n",
    "\n",
    "for tweet in public_tweets:\n",
    "    print(tweet.text)          #Imprime los tweets\n",
    "    analysis = TextBlob(tweet.text) \n",
    "    print(analysis.sentiment) #imprime el analisis de sentimiento\n",
    "    print(\"\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este solamente es una listado de stocks, se pretende meter esta información para procesarla sobre el API de una manera semejante pero puesto en twitts o información verbal. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#simbolos de stocks\n",
    "\n",
    "\n",
    "symbols_pfa = ['A',    'ADI',  'ALB',  'AMD',  'AMT',  'AMZN', 'AOS',  'APD',  'APH',  'AVGO', #1\n",
    "\t       'AVY',  'BA',   'BABA', 'BHGE', 'BWA',  'CAT',  'CME',  'CMI',  'CVX',  'DRI',  #2 \n",
    "               'EMN',  'FMC',  'GLW',  'HPE',  'HPQ',  'INTC', 'LEG',  'LLY',  'LMT',  'LRCX', #3\n",
    "               'LYB',  'MCD',  'MDB',  'MDT',  'MCHP', 'MRK',  'MTD',  'MU',   'NKE',  'NFLX', #4\n",
    "               'ORCL', 'PEP',  'PFE',  'PKI',  'QCOM', 'QRVO', 'SPLK', 'SQ',   'TMO',  'TSLA', #5\n",
    "               'TDG',  'TIF',  'TPR',  'V',    'WAT',  'WDAY', 'WDC',  'WU']   \t               #6    \n",
    "informationTechnology = ['FB', 'NVDA', 'SWKS', 'ANSS', 'TXN', 'ADBE', 'INTU', 'GOOGL', 'MA', 'CTSH',\n",
    "                         'EA', 'ACN',  'CDNS', 'AMAT', 'XLNX']\n",
    "healthCare = ['ISRG', 'ALGN', 'VRTX', 'INCY', 'ILMN', 'CERN', 'REGN', 'EW']\n",
    "consumerDiscretionary = ['CMG', 'ULTA', 'ROST', 'TSCO', 'GRMN', 'KORS', 'HD', 'SBUX']\n",
    "consumerStaples = ['MNST', 'HRL', 'CL', 'COST', 'SYY', 'HSY']\n",
    "industrials = ['FAST', 'EXPD', 'RHI', 'CHRW', 'JBHT', 'MMM']\n",
    "energy = ['VLO', 'PXD', 'COG', 'XEC']\n",
    "materials = [ 'IFF']\n",
    "telecommunicationsServices = ['VZ']\n",
    "jamesCramer = ['AAPL', 'ABT', 'AMGN', 'APC',   'BP',   'C',    'CMCSA', 'CRM', 'DHR', 'DIS', \n",
    "               'DWDP', 'EMR', 'FB',   'GOOGL', 'GS',   'HON',  'ITW',   'JNJ', 'JPM', 'JWN',  \n",
    "               'KSS',  'MMM', 'MSFT', 'NUE',   'NVDA', 'PYPL', 'RTN',   'SLB', 'TXT', 'UNH',\n",
    "               'WRK',  'XEC']\n",
    "cryptos = ['ADAUSDT', 'BCCUSDT', 'BNBUSDT',  'BTCUSDT',  'EOSUSDT', \n",
    "           'ETCUSDT', 'ETHUSDT', 'ICXUSDT',  'IOTAUSDT', 'LTCUSDT',\n",
    "           'NEOUSDT', 'ONTUSDT', 'QTUMUSDT', 'TRXUSDT',  'TUSDUSDT', \n",
    "           'VENUSDT', 'XLMUSDT', 'XRPUSDT']\n",
    "etfs = ['ACWI', 'AGG', 'BKF', 'DBO', 'DIA', 'EPP', 'EEM', 'EWA', 'EWC', 'EWG', 'EWH',   #1\n",
    "        'EWJ',  'EWT', 'EWU', 'EWQ', 'EWY', 'EWZ', 'EZU', 'FXI', 'IAU', 'IEO', 'IGV',   #2  \n",
    "        'ILF',  'ITB', 'IYC', 'IYE', 'IYF', 'IYK', 'IYR', 'IYW', 'IWM', 'IYH', 'IYJ',   #3 \n",
    "        'KBE', 'SLV', 'SHY', 'SPY', 'QQQ',  'XLF',]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalmente, se presenta por último una gráfica de sentimiento. Posterior al análisis se determina de una manera dicotómica (+/-) del sentimiento de la persona. Se presenta de manera estadistica por una distribución de cajas donde implican cuartiles y rangos. Entre el número medio se encuentre más hacia lo negativo, el sentimiento es negativo. Así, viceversa. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXEAAAEKCAYAAADkYmWmAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xa7f3eb8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#gráfica del análisis de sentimiento de los ultmos 100 tweets de trump, al parecer tiende a ser positivo el amigo\n",
    "sns.boxplot(x=\"sentiment\", data=df)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
